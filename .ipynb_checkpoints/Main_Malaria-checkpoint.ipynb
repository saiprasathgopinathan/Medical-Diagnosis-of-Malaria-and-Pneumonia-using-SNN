{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malaria/cell_images\n",
      "[]\n",
      "[INFO] building 'training' split\n",
      "[INFO] building 'validation' split\n",
      "[INFO] building 'testing' split\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from codes import config\n",
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# grab the paths to all input images in the original input directory\n",
    "# and shuffle them\n",
    "imagePaths = list(paths.list_images(config.ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * config.TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * config.VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]\n",
    "\n",
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "\t(\"training\", trainPaths, config.TRAIN_PATH),\n",
    "\t(\"validation\", valPaths, config.VAL_PATH),\n",
    "\t(\"testing\", testPaths, config.TEST_PATH)\n",
    "]\n",
    "\n",
    "\n",
    "# loop over the datasets\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\t# show which data split we are creating\n",
    "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
    "\n",
    "\t# if the output base output directory does not exist, create it\n",
    "\tif not os.path.exists(baseOutput):\n",
    "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "\t\tos.makedirs(baseOutput)\n",
    "\n",
    "\t# loop over the input image paths\n",
    "\tfor inputPath in imagePaths:\n",
    "\t\t# extract the filename of the input image along with its\n",
    "\t\t# corresponding class label\n",
    "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
    "\t\tlabel = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "\t\t# build the path to the label directory\n",
    "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "\t\t# if the label output directory does not exist, create it\n",
    "\t\tif not os.path.exists(labelPath):\n",
    "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "\t\t\tos.makedirs(labelPath)\n",
    "\n",
    "\t\t# construct the path to the destination image and then copy\n",
    "\t\t# the image itself\n",
    "\t\tp = os.path.sep.join([labelPath, filename])\n",
    "\t\tshutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet import ResNet\n",
    "from codes import config\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet_relu import ResNet\n",
    "from codes import config\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize our ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# define our set of callbacks and fit the model\n",
    "# callbacks = [LearningRateScheduler(poly_decay)]\n",
    "# H = model.fit_generator(\n",
    "# \ttrainGen,\n",
    "# \tsteps_per_epoch=totalTrain // BS,\n",
    "# \tvalidation_data=valGen,\n",
    "# \tvalidation_steps=totalVal // BS,\n",
    "# \tepochs=NUM_EPOCHS,\n",
    "# \tcallbacks=callbacks)\n",
    "\n",
    "# # reset the testing generator and then use our trained model to\n",
    "# # make predictions on the data\n",
    "# print(\"[INFO] evaluating network...\")\n",
    "# testGen.reset()\n",
    "# predIdxs = model.predict_generator(testGen,\n",
    "# \tsteps=(totalTest // BS) + 1)\n",
    "\n",
    "# # for each image in the testing set we need to find the index of the\n",
    "# # label with corresponding largest predicted probability\n",
    "# predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# # show a nicely formatted classification report\n",
    "# print(classification_report(testGen.classes, predIdxs,\n",
    "# \ttarget_names=testGen.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Found 2204 images belonging to 2 classes.\n",
      "Found 5512 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "620/620 [==============================] - 1791s 3s/step - loss: 0.8504 - acc: 0.8677 - val_loss: 0.7116 - val_acc: 0.9150\n",
      "Epoch 2/20\n",
      "620/620 [==============================] - 1759s 3s/step - loss: 0.5637 - acc: 0.9503 - val_loss: 0.5666 - val_acc: 0.9481\n",
      "Epoch 3/20\n",
      "620/620 [==============================] - 1809s 3s/step - loss: 0.4746 - acc: 0.9531 - val_loss: 0.4356 - val_acc: 0.9467\n",
      "Epoch 4/20\n",
      "620/620 [==============================] - 1801s 3s/step - loss: 0.4042 - acc: 0.9539 - val_loss: 0.3922 - val_acc: 0.9494\n",
      "Epoch 5/20\n",
      "620/620 [==============================] - 1806s 3s/step - loss: 0.4581 - acc: 0.9468 - val_loss: 0.4399 - val_acc: 0.9435\n",
      "Epoch 6/20\n",
      "620/620 [==============================] - 1802s 3s/step - loss: 0.3726 - acc: 0.9566 - val_loss: 0.3601 - val_acc: 0.9472\n",
      "Epoch 7/20\n",
      "620/620 [==============================] - 1793s 3s/step - loss: 0.3642 - acc: 0.9508 - val_loss: 0.3704 - val_acc: 0.9490\n",
      "Epoch 8/20\n",
      "620/620 [==============================] - 1800s 3s/step - loss: 0.3418 - acc: 0.9537 - val_loss: 0.3238 - val_acc: 0.9472\n",
      "Epoch 9/20\n",
      "620/620 [==============================] - 1802s 3s/step - loss: 0.2914 - acc: 0.9569 - val_loss: 0.3153 - val_acc: 0.9449\n",
      "Epoch 10/20\n",
      "620/620 [==============================] - 1804s 3s/step - loss: 0.2567 - acc: 0.9581 - val_loss: 0.2421 - val_acc: 0.9591\n",
      "Epoch 11/20\n",
      "620/620 [==============================] - 1810s 3s/step - loss: 0.2557 - acc: 0.9548 - val_loss: 0.2305 - val_acc: 0.9582\n",
      "Epoch 12/20\n",
      "620/620 [==============================] - 1808s 3s/step - loss: 0.2904 - acc: 0.9509 - val_loss: 0.2593 - val_acc: 0.9545\n",
      "Epoch 13/20\n",
      "620/620 [==============================] - 1811s 3s/step - loss: 0.2429 - acc: 0.9599 - val_loss: 0.2477 - val_acc: 0.9531\n",
      "Epoch 14/20\n",
      "620/620 [==============================] - 1810s 3s/step - loss: 0.2212 - acc: 0.9603 - val_loss: 0.2175 - val_acc: 0.9582\n",
      "Epoch 15/20\n",
      "620/620 [==============================] - 1811s 3s/step - loss: 0.2057 - acc: 0.9622 - val_loss: 0.2078 - val_acc: 0.9582\n",
      "Epoch 16/20\n",
      "620/620 [==============================] - 1807s 3s/step - loss: 0.2223 - acc: 0.9554 - val_loss: 0.2354 - val_acc: 0.9485\n",
      "Epoch 17/20\n",
      "620/620 [==============================] - 1793s 3s/step - loss: 0.2291 - acc: 0.9569 - val_loss: 0.2284 - val_acc: 0.9481\n",
      "Epoch 18/20\n",
      "620/620 [==============================] - 1808s 3s/step - loss: 0.2061 - acc: 0.9619 - val_loss: 0.2327 - val_acc: 0.9517\n",
      "Epoch 19/20\n",
      "620/620 [==============================] - 1805s 3s/step - loss: 0.1952 - acc: 0.9633 - val_loss: 0.2008 - val_acc: 0.9623\n",
      "Epoch 20/20\n",
      "620/620 [==============================] - 1809s 3s/step - loss: 0.1868 - acc: 0.9643 - val_loss: 0.1994 - val_acc: 0.9596\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.95      0.96      2756\n",
      "  Uninfected       0.95      0.98      0.96      2756\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5512\n",
      "   macro avg       0.96      0.96      0.96      5512\n",
      "weighted avg       0.96      0.96      0.96      5512\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-321957bbc7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet import ResNet\n",
    "from codes import config\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize our ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# define our set of callbacks and fit the model\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=callbacks)\n",
    "\n",
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BS) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "# create the base pre-trained model\n",
    "base_model = VGG19(weights=None, include_top=False , input_shape=(3,139, 139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "620/620 [==============================] - 20472s 33s/step - loss: 8.0834 - acc: 0.4985 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 2/20\n",
      "620/620 [==============================] - 22592s 36s/step - loss: 8.0688 - acc: 0.4994 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 3/20\n",
      "620/620 [==============================] - 19859s 32s/step - loss: 8.0794 - acc: 0.4987 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 4/20\n",
      "620/620 [==============================] - 20521s 33s/step - loss: 8.0769 - acc: 0.4989 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 5/20\n",
      "620/620 [==============================] - 23749s 38s/step - loss: 8.0907 - acc: 0.4980 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 6/20\n",
      "620/620 [==============================] - 22188s 36s/step - loss: 8.1037 - acc: 0.4972 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 7/20\n",
      "620/620 [==============================] - 20423s 33s/step - loss: 8.0720 - acc: 0.4992 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 8/20\n",
      "620/620 [==============================] - 74381s 120s/step - loss: 8.0802 - acc: 0.4987 - val_loss: 7.7554 - val_acc: 0.5188\n",
      "Epoch 9/20\n",
      " 49/620 [=>............................] - ETA: 4:45:37 - loss: 8.1618 - acc: 0.4936"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=19842 // 32,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=2204 // 32,\n",
    "\tepochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCEPTION V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "#print(os.listdir(\"/home/saiprasad/Desktop/project/dl-medical-imaging/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Found 2204 images belonging to 2 classes.\n",
      "Found 5512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet_batch_norm import ResNet\n",
    "from codes import config\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False , input_shape=(3, 139, 139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.load_weights(\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "620/620 [==============================] - 7990s 13s/step - loss: 0.1969 - acc: 0.9412 - val_loss: 0.2133 - val_acc: 0.9499\n",
      "Epoch 2/20\n",
      "620/620 [==============================] - 7837s 13s/step - loss: 0.1442 - acc: 0.9534 - val_loss: 0.1837 - val_acc: 0.9421\n",
      "Epoch 3/20\n",
      "620/620 [==============================] - 7924s 13s/step - loss: 0.1312 - acc: 0.9564 - val_loss: 0.1285 - val_acc: 0.9508\n",
      "Epoch 4/20\n",
      "620/620 [==============================] - 8125s 13s/step - loss: 0.1169 - acc: 0.9597 - val_loss: 0.1378 - val_acc: 0.9550\n",
      "Epoch 5/20\n",
      "620/620 [==============================] - 8352s 13s/step - loss: 0.1157 - acc: 0.9612 - val_loss: 0.2087 - val_acc: 0.9370\n",
      "Epoch 6/20\n",
      "620/620 [==============================] - 8775s 14s/step - loss: 0.1167 - acc: 0.9611 - val_loss: 0.1969 - val_acc: 0.9554\n",
      "Epoch 7/20\n",
      "620/620 [==============================] - 9646s 16s/step - loss: 0.1273 - acc: 0.9591 - val_loss: 0.1341 - val_acc: 0.9600\n",
      "Epoch 8/20\n",
      "620/620 [==============================] - 9485s 15s/step - loss: 0.1095 - acc: 0.9643 - val_loss: 0.1883 - val_acc: 0.9223\n",
      "Epoch 9/20\n",
      "620/620 [==============================] - 9012s 15s/step - loss: 0.1048 - acc: 0.9647 - val_loss: 0.1239 - val_acc: 0.9568\n",
      "Epoch 10/20\n",
      "620/620 [==============================] - 8781s 14s/step - loss: 0.1010 - acc: 0.9650 - val_loss: 0.1595 - val_acc: 0.9504\n",
      "Epoch 11/20\n",
      "620/620 [==============================] - 8120s 13s/step - loss: 0.0985 - acc: 0.9666 - val_loss: 0.0979 - val_acc: 0.9642\n",
      "Epoch 12/20\n",
      "620/620 [==============================] - 7657s 12s/step - loss: 0.0998 - acc: 0.9658 - val_loss: 0.1017 - val_acc: 0.9619\n",
      "Epoch 13/20\n",
      "620/620 [==============================] - 7886s 13s/step - loss: 0.0906 - acc: 0.9691 - val_loss: 0.1144 - val_acc: 0.9605\n",
      "Epoch 14/20\n",
      "620/620 [==============================] - 7935s 13s/step - loss: 0.0926 - acc: 0.9688 - val_loss: 0.1235 - val_acc: 0.9568\n",
      "Epoch 15/20\n",
      "620/620 [==============================] - 10988s 18s/step - loss: 0.0886 - acc: 0.9697 - val_loss: 0.1009 - val_acc: 0.9655\n",
      "Epoch 16/20\n",
      "620/620 [==============================] - 38178s 62s/step - loss: 0.1051 - acc: 0.9636 - val_loss: 0.1052 - val_acc: 0.9632\n",
      "Epoch 17/20\n",
      "620/620 [==============================] - 7620s 12s/step - loss: 0.0978 - acc: 0.9674 - val_loss: 0.1041 - val_acc: 0.9637\n",
      "Epoch 18/20\n",
      "620/620 [==============================] - 7419s 12s/step - loss: 0.1099 - acc: 0.9643 - val_loss: 0.0948 - val_acc: 0.9665\n",
      "Epoch 19/20\n",
      "620/620 [==============================] - 7422s 12s/step - loss: 0.0946 - acc: 0.9710 - val_loss: 0.1153 - val_acc: 0.9619\n",
      "Epoch 20/20\n",
      "620/620 [==============================] - 7418s 12s/step - loss: 0.0835 - acc: 0.9711 - val_loss: 0.0967 - val_acc: 0.9660\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=19842 // 32,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=2204 // 32,\n",
    "\tepochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.95      0.97      2756\n",
      "  Uninfected       0.95      0.98      0.97      2756\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5512\n",
      "   macro avg       0.97      0.97      0.97      5512\n",
      "weighted avg       0.97      0.97      0.97      5512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(5512 // 32) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,target_names=testGen.class_indices.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
