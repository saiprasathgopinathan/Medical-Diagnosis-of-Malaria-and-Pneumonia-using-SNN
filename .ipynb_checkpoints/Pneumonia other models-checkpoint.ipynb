{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning via InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "#print(os.listdir(\"/home/saiprasad/Desktop/project/dl-medical-imaging/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c857b24a29f6a9c08b97db1061d1ca787a2b903c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"/pneu/training1/\"\n",
    "TEST_DIR =  \"/pneu/testing/\"\n",
    "VAL_DIR =  \"/pneu/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "70b9a29f77e86bc117c6cbbb56b8ef3351be0d8e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            temp = Dir + nextDir                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = skimage.transform.resize(img,(139, 139, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e574dcb15d90d3d7ac16e6c6ec99870122fea8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "# datagen.fit(X_test)\n",
    "# datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e052d66b2bc0230cba4c258ca2b203c6ee3c49ff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b3e8e62ba15d81e498e99c343b1a2726c35f5d02",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False , input_shape=(3,139, 139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a360cfa0fb59bdc0320654f4d2f8ebdf17699606",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "802363ca2a8d86b07ee0ae5339f274204d098f9d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.load_weights(\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "faaf2b3ccc4577a1055a4be288b6ec0e59fd1a91",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d3e2aea33939fbddbbb74196e3e626c64eac6ee6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt, \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LARGE LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/pneu/training1/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce334cfaa52e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \tbatch_size=32)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# initialize the validation generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             interpolation=interpolation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, interpolation)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/pneu/training1/'"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False , input_shape=(3, 139, 139))\n",
    "\n",
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "base_model.load_weights(\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tTRAIN_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=32)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tVAL_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=32)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tTEST_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "78/78 [==============================] - 1119s 14s/step - loss: 0.8672 - acc: 0.6146 - val_loss: 1.7891 - val_acc: 0.4531\n",
      "Epoch 2/20\n",
      "78/78 [==============================] - 1142s 15s/step - loss: 0.7138 - acc: 0.6864 - val_loss: 2.3887 - val_acc: 0.2656\n",
      "Epoch 3/20\n",
      "78/78 [==============================] - 1114s 14s/step - loss: 0.6335 - acc: 0.7295 - val_loss: 2.8181 - val_acc: 0.4509\n",
      "Epoch 4/20\n",
      "78/78 [==============================] - 1086s 14s/step - loss: 0.6030 - acc: 0.7416 - val_loss: 2.6019 - val_acc: 0.4531\n",
      "Epoch 5/20\n",
      "78/78 [==============================] - 1092s 14s/step - loss: 0.5943 - acc: 0.7428 - val_loss: 2.0988 - val_acc: 0.4509\n",
      "Epoch 6/20\n",
      "78/78 [==============================] - 1106s 14s/step - loss: 0.5932 - acc: 0.7404 - val_loss: 2.1505 - val_acc: 0.3259\n",
      "Epoch 7/20\n",
      "78/78 [==============================] - 1129s 14s/step - loss: 0.5225 - acc: 0.7704 - val_loss: 0.8384 - val_acc: 0.6763\n",
      "Epoch 8/20\n",
      "78/78 [==============================] - 1145s 15s/step - loss: 0.5281 - acc: 0.7688 - val_loss: 0.8170 - val_acc: 0.7121\n",
      "Epoch 9/20\n",
      "78/78 [==============================] - 1147s 15s/step - loss: 0.4940 - acc: 0.7912 - val_loss: 0.6665 - val_acc: 0.6964\n",
      "Epoch 10/20\n",
      "78/78 [==============================] - 1160s 15s/step - loss: 0.4785 - acc: 0.8009 - val_loss: 1.1849 - val_acc: 0.4487\n",
      "Epoch 11/20\n",
      "78/78 [==============================] - 1146s 15s/step - loss: 0.5404 - acc: 0.7681 - val_loss: 3.3186 - val_acc: 0.3214\n",
      "Epoch 12/20\n",
      "78/78 [==============================] - 1157s 15s/step - loss: 0.4795 - acc: 0.7989 - val_loss: 1.8472 - val_acc: 0.5312\n",
      "Epoch 13/20\n",
      "78/78 [==============================] - 1134s 15s/step - loss: 0.5109 - acc: 0.7885 - val_loss: 0.6985 - val_acc: 0.6786\n",
      "Epoch 14/20\n",
      "78/78 [==============================] - 1147s 15s/step - loss: 0.5053 - acc: 0.7953 - val_loss: 0.9483 - val_acc: 0.6652\n",
      "Epoch 15/20\n",
      "78/78 [==============================] - 1129s 14s/step - loss: 0.5187 - acc: 0.7921 - val_loss: 1.2598 - val_acc: 0.4665\n",
      "Epoch 16/20\n",
      "78/78 [==============================] - 1120s 14s/step - loss: 0.5167 - acc: 0.7905 - val_loss: 0.6032 - val_acc: 0.7433\n",
      "Epoch 17/20\n",
      "78/78 [==============================] - 1123s 14s/step - loss: 0.4933 - acc: 0.7969 - val_loss: 8.2362 - val_acc: 0.3304\n",
      "Epoch 18/20\n",
      "78/78 [==============================] - 1114s 14s/step - loss: 0.4650 - acc: 0.8093 - val_loss: 0.8763 - val_acc: 0.6071\n",
      "Epoch 19/20\n",
      "78/78 [==============================] - 1113s 14s/step - loss: 0.4250 - acc: 0.8253 - val_loss: 0.5501 - val_acc: 0.7723\n",
      "Epoch 20/20\n",
      "78/78 [==============================] - 1143s 15s/step - loss: 0.4675 - acc: 0.8141 - val_loss: 4.7869 - val_acc: 0.4598\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=2500 // 32,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=468 // 32,\n",
    "\tepochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.86      0.95      0.90       314\n",
      "       VIRUS       0.72      0.80      0.76       537\n",
      "      NORMAL       0.54      0.38      0.45       321\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1172\n",
      "   macro avg       0.70      0.71      0.70      1172\n",
      "weighted avg       0.71      0.72      0.71      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(1172 // 32) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING RATE WITH 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 3 classes.\n",
      "Found 468 images belonging to 3 classes.\n",
      "Found 1172 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False , input_shape=(3, 139, 139))\n",
    "\n",
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "base_model.load_weights(\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tTRAIN_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=32)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tVAL_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=32)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tTEST_DIR,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(139, 139),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       1.00      0.78      0.87       314\n",
      "       VIRUS       0.73      0.88      0.80       537\n",
      "      NORMAL       0.67      0.59      0.63       321\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1172\n",
      "   macro avg       0.80      0.75      0.77      1172\n",
      "weighted avg       0.79      0.77      0.77      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(1172 // 32) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG - 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "# create the base pre-trained model\n",
    "base_model = VGG19(weights=None, include_top=False , input_shape=(3, 139, 139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 1759s 13s/step - loss: 0.4360 - acc: 0.8178 - val_loss: 0.5736 - val_acc: 0.8125\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 1867s 14s/step - loss: 0.4292 - acc: 0.8201 - val_loss: 0.5350 - val_acc: 0.8058\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 1833s 14s/step - loss: 0.4331 - acc: 0.8262 - val_loss: 0.5564 - val_acc: 0.8170\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 1791s 14s/step - loss: 0.4323 - acc: 0.8142 - val_loss: 3.1954 - val_acc: 0.6652\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 1804s 14s/step - loss: 0.4167 - acc: 0.8292 - val_loss: 0.4822 - val_acc: 0.7812\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 1806s 14s/step - loss: 0.4657 - acc: 0.8047 - val_loss: 3.5574 - val_acc: 0.2768\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 1800s 14s/step - loss: 0.5110 - acc: 0.7869 - val_loss: 1.1419 - val_acc: 0.7188\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 1905s 15s/step - loss: 0.4817 - acc: 0.8081 - val_loss: 0.6656 - val_acc: 0.6987\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 1912s 15s/step - loss: 0.4763 - acc: 0.8065 - val_loss: 0.5885 - val_acc: 0.7589\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 1810s 14s/step - loss: 0.4527 - acc: 0.8139 - val_loss: 0.6313 - val_acc: 0.7299\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 22987s 175s/step - loss: 0.4539 - acc: 0.8170 - val_loss: 0.9567 - val_acc: 0.7634\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 1597s 12s/step - loss: 0.4388 - acc: 0.8242 - val_loss: 0.4659 - val_acc: 0.7946\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 1597s 12s/step - loss: 0.4221 - acc: 0.8213 - val_loss: 0.5369 - val_acc: 0.8058\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 1591s 12s/step - loss: 0.4227 - acc: 0.8283 - val_loss: 0.4324 - val_acc: 0.8192\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 1594s 12s/step - loss: 0.4269 - acc: 0.8253 - val_loss: 0.4207 - val_acc: 0.8192\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 1593s 12s/step - loss: 0.4243 - acc: 0.8230 - val_loss: 0.5727 - val_acc: 0.7634\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 1593s 12s/step - loss: 0.4325 - acc: 0.8220 - val_loss: 0.5549 - val_acc: 0.7746\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 1594s 12s/step - loss: 0.4156 - acc: 0.8263 - val_loss: 0.6056 - val_acc: 0.7723\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 1594s 12s/step - loss: 0.4155 - acc: 0.8263 - val_loss: 0.6373 - val_acc: 0.8103\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 1593s 12s/step - loss: 0.4099 - acc: 0.8306 - val_loss: 0.4885 - val_acc: 0.8147\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=4216 // 32,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=468 // 32,\n",
    "\tepochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.86      0.99      0.92       314\n",
      "       VIRUS       0.78      0.84      0.81       537\n",
      "      NORMAL       0.73      0.51      0.60       321\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1172\n",
      "   macro avg       0.79      0.78      0.78      1172\n",
      "weighted avg       0.78      0.79      0.78      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(1172 // 32) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saiprasad/anaconda2/envs/py3/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(weights = None,include_top=False , input_shape=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.load_weights(\"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 829s 6s/step - loss: 0.9469 - acc: 0.6828 - val_loss: 1.2953 - val_acc: 0.6972\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 763s 6s/step - loss: 0.7514 - acc: 0.7215 - val_loss: 1.3104 - val_acc: 0.5045\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 779s 6s/step - loss: 0.5804 - acc: 0.7684 - val_loss: 0.5879 - val_acc: 0.7569\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 836s 6s/step - loss: 0.5531 - acc: 0.7843 - val_loss: 0.9915 - val_acc: 0.6835\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 818s 6s/step - loss: 0.5327 - acc: 0.7858 - val_loss: 0.5228 - val_acc: 0.7867\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 765s 6s/step - loss: 0.5324 - acc: 0.7902 - val_loss: 1.5676 - val_acc: 0.5482\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 760s 6s/step - loss: 0.5109 - acc: 0.7942 - val_loss: 0.5761 - val_acc: 0.7798\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 761s 6s/step - loss: 0.4970 - acc: 0.8031 - val_loss: 0.5923 - val_acc: 0.7683\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 760s 6s/step - loss: 0.4874 - acc: 0.8050 - val_loss: 0.6013 - val_acc: 0.7683\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 753s 6s/step - loss: 0.4999 - acc: 0.7987 - val_loss: 0.5883 - val_acc: 0.7592\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 751s 6s/step - loss: 0.5065 - acc: 0.7965 - val_loss: 0.7300 - val_acc: 0.6995\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 752s 6s/step - loss: 0.4895 - acc: 0.8008 - val_loss: 0.8291 - val_acc: 0.7546\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 753s 6s/step - loss: 0.4758 - acc: 0.8076 - val_loss: 1.8386 - val_acc: 0.5872\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 751s 6s/step - loss: 0.4631 - acc: 0.8157 - val_loss: 1.1788 - val_acc: 0.6330\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 753s 6s/step - loss: 0.4621 - acc: 0.8156 - val_loss: 2.7546 - val_acc: 0.4817\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 759s 6s/step - loss: 0.4424 - acc: 0.8134 - val_loss: 0.5679 - val_acc: 0.7729\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 763s 6s/step - loss: 0.4462 - acc: 0.8159 - val_loss: 0.5369 - val_acc: 0.7812\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 762s 6s/step - loss: 0.4332 - acc: 0.8229 - val_loss: 1.1254 - val_acc: 0.7064\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 764s 6s/step - loss: 0.4381 - acc: 0.8222 - val_loss: 0.5501 - val_acc: 0.7729\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 762s 6s/step - loss: 0.4210 - acc: 0.8313 - val_loss: 0.7638 - val_acc: 0.7317\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=4216 // 32,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=468 // 32,\n",
    "\tepochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     NORMAL       0.71      1.00      0.83       314\n",
      "  PNEUMONIA       0.70      0.90      0.79       537\n",
      "      VIRUS       0.83      0.09      0.16       321\n",
      "\n",
      "avg / total       0.74      0.70      0.63      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(1172 // 32) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
