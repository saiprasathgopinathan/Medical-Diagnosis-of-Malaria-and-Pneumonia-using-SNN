{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Self intialization of weights and to maintain the variance of the weights\n",
    "# to remain the same as it passes through layers Xavier initizalization is used\n",
    "# 2) variance to remain the same as we pass through each layer. \n",
    "# 3) E(xi)^2 * var(wi) + E(wi)^ 2* var(xi) + var(wi)* var(xi) where E() = mean which is zero\n",
    "# 4) var(wixi) = var(wi)* var(xi) + b since b is constant and has zero variance its ignored\n",
    "# 5) var(wx) = var(wi) * var(xi)+......+ var(wn) * var(xn)\n",
    "# 6) var(y) = N * var(wi) * var(xi)\n",
    "# 7) N * var(wi) = 1    , \n",
    "# 8) var(wi) = 1/N  reason =  initialization for SNN will help the output of SNN model\n",
    "# to stay at normalized point at zero mean and unit variance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (1) scale inputs to zero mean and unit variance using lambda\n",
    "# 2) If network deeper SELU perfroms good\n",
    "# 3) One hypothesis regarding SELU performance is its ability to normalize the layer output which makes \n",
    "# it less prone to gradient issue\n",
    "# 4) The deeper the network goes the mean and variance move towards the fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "[INFO] building 'training' split\n",
      "[INFO] building 'validation' split\n",
      "[INFO] building 'testing' split\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python build_dataset.py\n",
    "\n",
    "# import the necessary packages\n",
    "from codes import config1\n",
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# grab the paths to all input images in the original input directory\n",
    "# and shuffle them\n",
    "imagePaths = list(paths.list_images(config1.ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * config1.TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * config1.VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]\n",
    "\n",
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "\t(\"training\", trainPaths, config1.TRAIN_PATH),\n",
    "\t(\"validation\", valPaths, config1.VAL_PATH),\n",
    "\t(\"testing\", testPaths, config1.TEST_PATH)\n",
    "]\n",
    "\n",
    "# loop over the datasets\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\t# show which data split we are creating\n",
    "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
    "\n",
    "\t# if the output base output directory does not exist, create it\n",
    "\tif not os.path.exists(baseOutput):\n",
    "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "\t\tos.makedirs(baseOutput)\n",
    "\n",
    "\t# loop over the input image paths\n",
    "\tfor inputPath in imagePaths:\n",
    "\t\t# extract the filename of the input image along with its\n",
    "\t\t# corresponding class label\n",
    "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
    "\t\tlabel = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "\t\t# build the path to the label directory\n",
    "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "\t\t# if the label output directory does not exist, create it\n",
    "\t\tif not os.path.exists(labelPath):\n",
    "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "\t\t\tos.makedirs(labelPath)\n",
    "\n",
    "\t\t# construct the path to the destination image and then copy\n",
    "\t\t# the image itself\n",
    "\t\tp = os.path.sep.join([labelPath, filename])\n",
    "\t\tshutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            temp = Dir + nextDir                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = resize(img,(64, 64, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TRAIN_DIR = \"/home/saiprasad/Desktop/project/dl-medical-imaging/pneu/training1/\"\n",
    "TEST_DIR =  \"/home/saiprasad/Desktop/project/dl-medical-imaging/pneu/testing/\"\n",
    "VAL_DIR =  \"/home/saiprasad/Desktop/project/dl-medical-imaging/pneu/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:19<00:00, 27.17it/s]\n",
      "100%|██████████| 321/321 [00:13<00:00, 24.26it/s]\n",
      "100%|██████████| 314/314 [00:25<00:00, 12.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test , y_test = get_data(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:27<00:00, 30.84it/s]\n",
      "100%|██████████| 930/930 [00:41<00:00, 22.59it/s]\n",
      "100%|██████████| 730/730 [01:04<00:00, 11.33it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:07<00:00, 28.94it/s]\n",
      "100%|██████████| 139/139 [00:05<00:00, 25.46it/s]\n",
      "100%|██████████| 126/126 [00:10<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val,y_val = get_data(VAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_val = to_categorical(y_val,3)\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(2500,64,64,3)\n",
    "X_test=X_test.reshape(1172,64,64,3)\n",
    "X_val = X_val.reshape(468,64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2500, 64, 64, 3), (1172, 64, 64, 3), (468, 64, 64, 3))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from codes.resnet import ResNet\n",
    "from keras.optimizers import SGD\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 0.001\n",
    "BS = 32\n",
    "\n",
    "model = ResNet.build(64, 64,3, 3, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train,y_train,steps_per_epoch=2500//32, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4216 images belonging to 3 classes.\n",
      "Found 468 images belonging to 3 classes.\n",
      "Found 1172 images belonging to 3 classes.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 64, 64, 3)    256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 64, 64, 64)   4800        batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 64, 64, 64)   256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 64, 64, 64)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 32, 32, 64)   128         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 32, 32, 64)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 32)   2048        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 32, 32, 32)   128         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 32, 32, 32)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 32, 32, 32)   9216        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 32, 32, 32)   128         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 32, 32, 32)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 32, 32, 128)  4096        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 32, 32, 128)  8192        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 32, 32, 128)  0           conv2d_90[0][0]                  \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 32, 32, 128)  128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 32, 32, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 32, 32, 32)   4096        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 32)   128         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 32, 32, 32)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 32, 32, 32)   9216        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 32, 32)   128         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 32)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 128)  4096        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 32, 128)  0           conv2d_94[0][0]                  \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 32, 32, 128)  128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, 32, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 32)   4096        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 32, 32, 32)   128         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 32, 32, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 32)   9216        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 32, 32, 32)   128         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 32, 32, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 32, 32, 128)  4096        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 128)  0           conv2d_97[0][0]                  \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 32, 32, 128)  128         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 32, 32, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 32, 32, 64)   8192        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 32, 32, 64)   128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 32, 32, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   36864       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 16, 64)   64          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 64)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 256)  16384       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 256)  32768       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 256)  0           conv2d_100[0][0]                 \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 256)  64          add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 16, 16, 256)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   16384       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 64)   64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 64)   36864       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   64          conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 256)  16384       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 256)  0           conv2d_104[0][0]                 \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 256)  64          add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 256)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 64)   16384       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 64)   64          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   36864       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 64)   64          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 256)  16384       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 256)  0           conv2d_107[0][0]                 \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 256)  64          add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 256)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   16384       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   64          conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   36864       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 64)   64          conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 256)  16384       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 16, 16, 256)  0           conv2d_110[0][0]                 \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 256)  64          add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 256)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 128)  32768       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 128)  64          conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 128)    147456      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 128)    32          conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 512)    65536       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 512)    131072      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 512)    0           conv2d_113[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 512)    32          add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 512)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 128)    65536       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 128)    32          conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 128)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 128)    147456      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 8, 128)    32          conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 128)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 512)    65536       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 512)    0           conv2d_117[0][0]                 \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 512)    32          add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 512)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 128)    65536       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 128)    32          conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 128)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 128)    147456      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 128)    32          conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 128)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 512)    65536       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 8, 512)    0           conv2d_120[0][0]                 \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 512)    32          add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 512)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 128)    65536       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 128)    32          conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 128)    147456      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 128)    32          conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 128)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 512)    65536       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 8, 8, 512)    0           conv2d_123[0][0]                 \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 512)    32          add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 512)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 128)    65536       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 128)    32          conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 128)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 128)    147456      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 128)    32          conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 128)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 512)    65536       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 8, 8, 512)    0           conv2d_126[0][0]                 \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 512)    32          add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 512)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 128)    65536       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 128)    32          conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 128)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 128)    147456      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 128)    32          conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 512)    65536       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 8, 8, 512)    0           conv2d_129[0][0]                 \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 512)    32          add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 512)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 512)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            1026        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 2)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,140,002\n",
      "Trainable params: 2,138,386\n",
      "Non-trainable params: 1,616\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_126 to have shape (None, 2) but got array with shape (32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3e8e69fd7037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotalVal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \tcallbacks=callbacks)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# reset the testing generator and then use our trained model to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1831\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/saiprasad/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_126 to have shape (None, 2) but got array with shape (32, 3)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet import ResNet\n",
    "from codes import config1\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 0.001\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config1.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config1.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config1.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig1.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig1.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig1.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize our ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# define our set of callbacks and fit the model\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=callbacks)\n",
    "\n",
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BS) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4216 images belonging to 3 classes.\n",
      "Found 468 images belonging to 3 classes.\n",
      "Found 1172 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "131/131 [==============================] - 414s 3s/step - loss: 1.0833 - acc: 0.7530 - val_loss: 0.9567 - val_acc: 0.8118\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 432s 3s/step - loss: 0.9307 - acc: 0.8170 - val_loss: 1.1904 - val_acc: 0.6979\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 439s 3s/step - loss: 0.9000 - acc: 0.8229 - val_loss: 0.8389 - val_acc: 0.8423\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 446s 3s/step - loss: 0.8582 - acc: 0.8266 - val_loss: 0.8852 - val_acc: 0.7902\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 433s 3s/step - loss: 0.8243 - acc: 0.8344 - val_loss: 1.2363 - val_acc: 0.7247\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 438s 3s/step - loss: 0.7974 - acc: 0.8409 - val_loss: 1.0141 - val_acc: 0.7307\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 435s 3s/step - loss: 0.7845 - acc: 0.8395 - val_loss: 0.8006 - val_acc: 0.8222\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 437s 3s/step - loss: 0.7678 - acc: 0.8422 - val_loss: 0.8408 - val_acc: 0.8118\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 431s 3s/step - loss: 0.7457 - acc: 0.8462 - val_loss: 1.7102 - val_acc: 0.6652\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 441s 3s/step - loss: 0.7284 - acc: 0.8490 - val_loss: 0.7080 - val_acc: 0.8527\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 436s 3s/step - loss: 0.7172 - acc: 0.8479 - val_loss: 0.6965 - val_acc: 0.8504\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 424s 3s/step - loss: 0.7002 - acc: 0.8526 - val_loss: 0.6908 - val_acc: 0.8542\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 430s 3s/step - loss: 0.6969 - acc: 0.8547 - val_loss: 0.6651 - val_acc: 0.8579\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 433s 3s/step - loss: 0.6778 - acc: 0.8555 - val_loss: 0.6431 - val_acc: 0.8728\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 431s 3s/step - loss: 0.6671 - acc: 0.8584 - val_loss: 0.6390 - val_acc: 0.8750\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 425s 3s/step - loss: 0.6646 - acc: 0.8574 - val_loss: 0.6728 - val_acc: 0.8661\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 424s 3s/step - loss: 0.6471 - acc: 0.8647 - val_loss: 0.6627 - val_acc: 0.8668\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 425s 3s/step - loss: 0.6461 - acc: 0.8638 - val_loss: 0.6375 - val_acc: 0.8683\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 426s 3s/step - loss: 0.6384 - acc: 0.8666 - val_loss: 0.6142 - val_acc: 0.8772\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 432s 3s/step - loss: 0.6335 - acc: 0.8695 - val_loss: 0.6151 - val_acc: 0.8728\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.87      0.97      0.92       314\n",
      "       VIRUS       0.79      0.85      0.82       537\n",
      "      NORMAL       0.72      0.54      0.62       321\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1172\n",
      "   macro avg       0.79      0.79      0.78      1172\n",
      "weighted avg       0.79      0.80      0.79      1172\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a7a0058aead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet import ResNet\n",
    "from codes import config1\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config1.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config1.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config1.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig1.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig1.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig1.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize our ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 3, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# define our set of callbacks and fit the model\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=callbacks)\n",
    "\n",
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BS) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LARGER LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4216 images belonging to 3 classes.\n",
      "Found 468 images belonging to 3 classes.\n",
      "Found 1172 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "131/131 [==============================] - 462s 4s/step - loss: 0.9937 - acc: 0.7890 - val_loss: 0.9140 - val_acc: 0.8251\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 478s 4s/step - loss: 0.9080 - acc: 0.8353 - val_loss: 0.9562 - val_acc: 0.8244\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 498s 4s/step - loss: 0.8937 - acc: 0.8378 - val_loss: 1.1061 - val_acc: 0.7589\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 510s 4s/step - loss: 0.8811 - acc: 0.8437 - val_loss: 0.8459 - val_acc: 0.8504\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 542s 4s/step - loss: 0.8666 - acc: 0.8473 - val_loss: 0.8856 - val_acc: 0.8348\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 503s 4s/step - loss: 0.8609 - acc: 0.8510 - val_loss: 0.8296 - val_acc: 0.8616\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 485s 4s/step - loss: 0.8509 - acc: 0.8567 - val_loss: 0.8425 - val_acc: 0.8698\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 479s 4s/step - loss: 0.8426 - acc: 0.8610 - val_loss: 0.8649 - val_acc: 0.8609\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 478s 4s/step - loss: 0.8376 - acc: 0.8627 - val_loss: 0.8328 - val_acc: 0.8646\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 461s 4s/step - loss: 0.8268 - acc: 0.8669 - val_loss: 0.8262 - val_acc: 0.8609\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 459s 4s/step - loss: 0.8254 - acc: 0.8654 - val_loss: 0.8369 - val_acc: 0.8624\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 457s 3s/step - loss: 0.8167 - acc: 0.8700 - val_loss: 0.8453 - val_acc: 0.8415\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 461s 4s/step - loss: 0.8157 - acc: 0.8686 - val_loss: 0.8235 - val_acc: 0.8549\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 462s 4s/step - loss: 0.8111 - acc: 0.8678 - val_loss: 0.8337 - val_acc: 0.8750\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 463s 4s/step - loss: 0.8082 - acc: 0.8716 - val_loss: 0.7982 - val_acc: 0.8743\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 474s 4s/step - loss: 0.8010 - acc: 0.8727 - val_loss: 0.7959 - val_acc: 0.8668\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 488s 4s/step - loss: 0.8017 - acc: 0.8757 - val_loss: 0.7991 - val_acc: 0.8750\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 481s 4s/step - loss: 0.7936 - acc: 0.8782 - val_loss: 0.7831 - val_acc: 0.8780\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 472s 4s/step - loss: 0.7967 - acc: 0.8731 - val_loss: 0.7909 - val_acc: 0.8765\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 478s 4s/step - loss: 0.7858 - acc: 0.8815 - val_loss: 0.7783 - val_acc: 0.8772\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   PNEUMONIA       0.90      0.96      0.93       314\n",
      "       VIRUS       0.77      0.86      0.82       537\n",
      "      NORMAL       0.74      0.54      0.63       321\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1172\n",
      "   macro avg       0.80      0.79      0.79      1172\n",
      "weighted avg       0.80      0.80      0.79      1172\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3621b6c7532d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from codes.resnet import ResNet\n",
    "from codes import config1\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 20\n",
    "INIT_LR = 1e-2\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    "\n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "\n",
    "\t# return the new learning rate\n",
    "\treturn alpha\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config1.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config1.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config1.TEST_PATH)))\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig1.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig1.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig1.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize our ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 3, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# define our set of callbacks and fit the model\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=callbacks)\n",
    "\n",
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BS) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
